{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import itertools\n",
    "import shap\n",
    "import numpy as np\n",
    "import scipy.special\n",
    "import time\n",
    "import warnings\n",
    "from skimage.segmentation import slic, mark_boundaries\n",
    "from skimage.transform import resize\n",
    "from skimage.filters import gaussian, hessian\n",
    "from skimage.util import random_noise\n",
    "from torchvision.transforms.v2.functional import gaussian_blur, posterize, solarize, adjust_brightness, adjust_contrast, adjust_gamma, adjust_saturation\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('images/cat_guitar.jpg')\n",
    "plt.imshow(img)\n",
    "\n",
    "img2 = Image.open('images/LabradorPlayingGuitar.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = torchvision.transforms.functional.pil_to_tensor(img)\n",
    "img_array = np.array(img)\n",
    "img_array2 = resize(np.array(img2), img_array.shape)\n",
    "a = slic(img_array, n_segments=50, compactness=10, start_label=0)\n",
    "\n",
    "print(img_array.shape)\n",
    "\n",
    "plt.imshow(mark_boundaries(img_array, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments, masks = test.slic_segmenter(img_array, nbr_segments=50, compactness=10)\n",
    "_, rise_masks = test.grid_segmenter(img_array, 10, 10, True)\n",
    "\n",
    "masks = test.fade_segment_masks(masks, sigma=10.0)\n",
    "\n",
    "print(_.shape)\n",
    "\n",
    "M = np.unique(segments).shape[0]\n",
    "samples = test.shap_sampler(M, sample_size=M*6+2)\n",
    "ciu_samples = test.naive_ciu_sampler(M,inverse=False)\n",
    "rise_samples = test.random_sampler(rise_masks.shape[0], sample_size=50)\n",
    "\n",
    "a = test.perturbation_masks(rise_masks, rise_samples)\n",
    "\n",
    "perturbed_image, samples = test.single_color_pertuber(img_array, masks, samples, np.array((190,190,190)))\n",
    "ciu_perturbed_image, ciu_samples = test.single_color_pertuber(img_array, masks, ciu_samples, np.array((190,190,190)))\n",
    "#rise_perturbed_image, rise_samples = test.single_color_pertuber(img_array, rise_masks, rise_samples, np.array((190,190,190)))\n",
    "\n",
    "print(np.max(img_array), np.max(img_array2))\n",
    "rise_perturbed_image, rise_samples = test.replace_image_perturbation(img_array, img_array2*255, test.perturbation_masks(rise_masks, rise_samples), rise_samples)\n",
    "\n",
    "print(samples[1], samples[14], samples[73], rise_samples[0])\n",
    "plt.figure()\n",
    "plt.imshow(perturbed_image[1])\n",
    "plt.figure()\n",
    "plt.imshow(perturbed_image[14])\n",
    "plt.figure()\n",
    "plt.imshow(perturbed_image[73])\n",
    "plt.figure()\n",
    "plt.imshow(rise_perturbed_image[0])\n",
    "plt.figure()\n",
    "plt.imshow(a[0])\n",
    "plt.figure()\n",
    "plt.imshow(img_array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = torchvision.models.alexnet(weights='IMAGENET1K_V1')\n",
    "alexnet.eval()\n",
    "\n",
    "\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "transforms = v2.Compose([\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    v2.Resize((224,224))\n",
    "])\n",
    "\n",
    "x = transforms(torch.from_numpy(perturbed_image/255).permute((0,3,1,2))).float()\n",
    "ciu_x = transforms(torch.from_numpy(ciu_perturbed_image/255).permute((0,3,1,2))).float()\n",
    "rise_x = transforms(torch.from_numpy(rise_perturbed_image/255).permute((0,3,1,2))).float()\n",
    "\n",
    "y = alexnet(x)\n",
    "ciu_y = alexnet(ciu_x)\n",
    "rise_y = alexnet(rise_x)\n",
    "\n",
    "idx = y[1].argmax()\n",
    "print(idx)\n",
    "\n",
    "sorted, indices = y[1].sort(descending=True)\n",
    "print(indices)\n",
    "\n",
    "y = y.detach().numpy()\n",
    "ciu_y = ciu_y.detach().numpy()\n",
    "rise_y = rise_y.detach().numpy()\n",
    "\n",
    "cat_idx = 281\n",
    "guitar_idx = 402\n",
    "\n",
    "\n",
    "cat_ys = y[:,cat_idx]\n",
    "guitar_ys = y[:,guitar_idx]\n",
    "\n",
    "print(ciu_y[:,cat_idx])\n",
    "\n",
    "ciu_cat_ys = ciu_y[:,cat_idx]\n",
    "ciu_guitar_ys = ciu_y[:,guitar_idx]\n",
    "\n",
    "rise_cat_ys = rise_y[:,cat_idx]\n",
    "rise_guitar_ys = rise_y[:,guitar_idx]\n",
    "\n",
    "\n",
    "\n",
    "cat_shaps, cat_base_shap, _ = test.shap_values(cat_ys, samples)\n",
    "guitar_shaps, guitar_base, _ = test.shap_values(guitar_ys,  samples)\n",
    " \n",
    "cat_ci, cat_cu, cat_infl, _ = test.original_ciu_values(ciu_cat_ys, ciu_samples)#, inverse=False)\n",
    "guitar_ci, guitar_cu, guitar_infl, _ = test.original_ciu_values(ciu_guitar_ys, ciu_samples)#, inverse=False)\n",
    "\n",
    "cat_ci2, cat_cu2, cat_infl2, ciu_samples2 = test.ciu_values(cat_ys, samples)#, inverse=False)\n",
    "guitar_ci2, guitar_cu2, guitar_infl2, ciu_samples2 = test.ciu_values(guitar_ys, samples)#, inverse=False)\n",
    "\n",
    "ciu2_catmax = np.nanargmax(cat_infl2)\n",
    "\n",
    "rise_perturbed_masks = test.perturbation_masks(rise_masks, rise_samples)\n",
    "\n",
    "cat_rise, _ = test.rise_values(rise_cat_ys, rise_perturbed_masks)\n",
    "guitar_rise, _ = test.rise_values(rise_guitar_ys, rise_perturbed_masks)\n",
    "\n",
    "#print(ciu_samples)\n",
    "\n",
    "#plt.imshow(perturbed_image[np.argmax(cat_shaps[0][:-1])+2])\n",
    "#plt.figure()\n",
    "#plt.imshow(perturbed_image[np.argmax(guitar_shaps[0][:-1])+2])\n",
    "#plt.figure()\n",
    "plt.imshow(ciu_perturbed_image[np.argmax(cat_shaps)])\n",
    "plt.figure()\n",
    "plt.imshow(ciu_perturbed_image[np.argmax(guitar_shaps)])\n",
    "#plt.figure()\n",
    "#plt.imshow(rise_masks[np.argmax(cat_rise)])\n",
    "#plt.figure()\n",
    "#plt.imshow(rise_masks[np.argmax(guitar_rise)])\n",
    "plt.figure()\n",
    "plt.imshow(cat_rise)\n",
    "plt.figure()\n",
    "plt.imshow(guitar_rise)\n",
    "plt.figure()\n",
    "plt.imshow(ciu_perturbed_image[np.nanargmax(cat_infl)])\n",
    "plt.figure()\n",
    "plt.imshow(ciu_perturbed_image[np.nanargmax(guitar_infl)])\n",
    "#plt.figure()\n",
    "#plt.imshow(ciu_perturbed_image[np.argwhere(np.max(cat_ci) ==cat_ciu)[0,0]])\n",
    "#plt.figure()\n",
    "#plt.imshow(ciu_perturbed_image[np.argwhere(np.max(guitar_ci) ==guitar_ciu)[1,0]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
